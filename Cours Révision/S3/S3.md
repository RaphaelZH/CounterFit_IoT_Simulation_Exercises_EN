# INTRODUCTION AUX SYSTÈMES RÉPARTIS

## 1 Introduction aux Threads

*Nous construisons des processeurs virtuels dans des logiciels, sur des processeurs physiques*

- Processeur : Fournit un ensemble d’instructions ainsi que la possibilité d’exécuter automatiquement une série de ces instructions.

- Thread : Un processeur logiciel minimal dans le contexte duquel une série d’instructions peut être exécutée. L’enregistrement d’un contexte de Threads implique la suspension de l’exécution et la sauvegarde de toutes les données nécessaires à la reprise de l’exécution dans le futur.

- Processus : processeur logiciel dans le contexte duquel un ou plusieurs Threads peuvent être exécutés.

> Remarquer qu'exécuter un Threads c’est exécuter un ensemble d’instructions dans le contexte de ce Threads.


### 1.1 Changement de contexte

- Contextes

	- Contexte du processeur : La collection minimale de valeurs stockées dans les registres d’un processeur utilisé pour l’exécution d’une série d’instructions (par exemple, pointeur de pile, registres d’adressage, compteur de programme).

	- Contexte de Threads : collection minimale de valeurs stockées dans les registres et la mémoire, utilisée pour l’exécution d’une série d’instructions (c’est-à-dire le contexte du processeur, l’état).

	- Contexte de processus : la collection minimale de valeurs stockées dans les registres et la mémoire, utilisée pour l’exécution d’un Threads (c’est-à-dire le contexte du Threads, mais maintenant plus au moins les valeurs de registre MMU).

- Remarques :

	- Les Threads partagent le même espace d’adressage.
	
	- Le changement de contexte de Threads peut être effectué de manière totalement indépendante du système d’exploitation.
	
	- Le changement de contexte de processus est généralement (un peu) plus coûteux car il implique le système d’exploitation en exécutant des interruptions.
	
	- La création et la destruction de Threads est beaucoup moins chère que la création et la destruction des processus.
























| ![L’organisation du système centralisé vs décentralisé vs réparti](./Figures/01.%20Figure%201.png) |
|:--------------------------------------------------------------------------------------------------:|
|           **Figure 1 : L’organisation du système centralisé vs décentralisé vs réparti**           |

### 1.1 Deux points de vue sur la réalisation de systèmes informatiques en réseau

- **Vue intégrative** : connecter des systèmes informatiques en réseau existants dans un système plus vaste.

- **Vue d’ensemble** : un système informatique en réseau existant est complété par des ordinateurs supplémentaires.

### 1.2 Deux types de systèmes de réseaux informatiques basés sur les deux points de vue

- Un système décentralisé est un système informatique en réseau dans lequel les processus et les ressources sont nécessairement répartis sur plusieurs ordinateurs.

- Un système réparti est un système informatique en réseau dans lequel les processus et les ressources sont suffisamment répartis sur plusieurs ordinateurs.

> Remarquer que la décentralisation est une contrainte de conception, la répartition est un choix de conception.

## 2 Objectifs globaux de conception des systèmes répartis

- Soutenir le partage des ressources.

- Transparence de la distribution.

- Ouverture.

- Évolutivité.

### 2.1 Transparence de la distribution dans les systèmes distribués

| ![Réaliser la transparence de la distribution grâce à une couche middleware](./Figures/02.%20Figure%202.png) |
|:------------------------------------------------------------------------------------------------------------:|
|           **Figure 2 : Réaliser la transparence de la distribution grâce à une couche middleware**           |

#### 2.1.1 Qu’est-ce que la transparence ?

- Phénomène par lequel un système réparti tente de cacher le fait que ses processus et ses ressources sont physiquement répartis sur plusieurs ordinateurs, éventuellement séparés par de grandes distances.

- La transparence de la distribution est gérée par de nombreuses techniques différentes dans une couche entre les applications et les systèmes d’exploitation : une couche d’intergiciel (middleware).

#### 2.1.2 Différentes formes de transparence dans un système distribué

| Type de transparence                      | Description                                                                   |
|-------------------------------------------|-------------------------------------------------------------------------------|
| Accès                                     | Cache les différences des représentations de données et l’accès aux objets    |
| Localisation                              | Cache la localisation dans laquelle l’objet est stocké                        |
| Relocalisation, basculement, ou migration | Cache le fait que l’objet peut changer de localisation durant son utilisation |
| Réplication                               | Cache le fait que l’objet est répliqué                                        |
| Concurrence                               | Cache le fait que l’objet est utilisé par plusieurs utilisateurs (partagé)    |
| Pannes                                    | Cache les pannes et les reprises après la panne d’un objet                    |
	
> Remarquer qu’un objet peut être une ressource ou un processus.

#### 2.1.3 Degré de transparence

- Viser une transparence totale de la distribution est peut-être exagéré.

	- Il existe des latences de communication qui ne peuvent pas être cachées.

	- Cacher complètement les défaillances des réseaux et des nœuds est (théoriquement et pratiquement) impossible. Par exemple :
	
		- Vous ne pouvez pas distinguer un ordinateur lent d’un ordinateur défaillant.

		- Vous ne pouvez jamais être sûr qu’un serveur a réellement effectué une opération avant une panne.
	
	- Une transparence totale coûtera cher aux performances. Exposant la distribution du système, il est possible de :

		- Garder les répliques exactement à jour, ce qui prend du temps.

		- Vider immédiatement les opérations d’écriture sur le disque pour la tolérance aux pannes.

- Il peut être bon d’exposer la distribution.

	- Utiliser des services basés sur la localisation (trouver vos amis à proximité).

	- Lorsque vous interagissez avec des utilisateurs dans des fuseaux horaires différents.
	
	- Lorsqu’il est plus facile pour un utilisateur de comprendre ce qui se passe (par exemple, lorsqu’un serveur ne répond pas pendant une longue période, signalez-le comme défaillant).

> Remarquer que la transparence de la distribution est un bon objectif, mais l’atteindre peut être coûteux, elle doit être visée d’une manière réaliste et pragmatique.

### 2.2 Fiabilité dans les systèmes distribués

- Notions de base :

	- Un composant fournit des services aux clients.

	- Les composants peuvent être des processus ou des canaux.

	- Pour fournir des services, le composant peut avoir besoin des services d’autres composants, c’est-à-dire qu’un composant peut dépendre d’un autre composant.

- Spécifiquement :

	- Un composant $C$ dépend de $C’$ si l’exactitude du comportement de $C$ dépend de l’exactitude du comportement de $C’$.

#### 2.2.1 Exigences relatives à la fiabilité de fonctionnement

| Exigence       | Description                                                    |
|----------------|----------------------------------------------------------------|
| Disponibilité  | Capacité du système à fournir le service                       |
| Stabilité      | Capacité d’un composant à fournir le service                   |
| Sûreté         | Faible probabilité de catastrophe, surtout avec dégâts humains |
| Maintenabilité | La facilité de réparer le système en cas de panne              |

#### 2.2.2 Indicateurs traditionnels

- Temps moyen jusqu’à la défaillance (*MTTF*) : temps moyen jusqu’à ce qu’un composant tombe en panne.

- Temps moyen de réparation (*MTTR*) : temps moyen nécessaire à la réparation d’un composant.

- Temps moyen entre les pannes (*MTBF*) : simplement *MTTF* + *MTTR*

#### 2.2.3 Panne, erreur, défaut

| Concept | Description                                                         | Exemple                            |
|---------|---------------------------------------------------------------------|------------------------------------|
| Panne   | Un composant qui ne se comporte pas conformément à sa spécification | Un programme qui a craché          |
| Erreur  | Partie du composant qui peut causer une panne                       | Une ligne de code incorrecte (bug) |
| Défaut  | Cause d’une erreur                                                  | La faute dans la ligne             |

### 2.3 Sécurité dans les systèmes distribués

- Un système réparti qui n’est pas sécurisé n’est pas fiable

- Ce dont nous avons besoin :

	- Confidentialité : les renseignements ne sont divulgués qu’aux parties autorisées.
	
	- Intégrité : S’assurer que les modifications apportées aux ressources d’un système ne peuvent être apportées que de manière autorisée.

#### 2.3.1 Autorisation, authentification, confiance

- Authentification : vérification de l’exactitude d’une identité revendiquée

- Autorisation : une entité identifiée dispose-t-elle des droits d’accès appropriés ?

- Confiance : une entité peut être assurée qu’une autre effectuera des actions particulières en fonction d’une attente spécifique.

#### 2.3.2 Mécanismes de sécurité

- Rester simple :

	- Il s’agit de chiffrer et de déchiffrer les données à l’aide de clés de sécurité.

- Notation :

	- $K(donnée)$ indique que nous utilisons la clé $K$ pour chiffrer/déchiffrer les données.
	
- Système de cryptage symétrique :

	- Avec la clé de cryptage $E_{K}$ et la clé de décryptage $D_{K}$ :
	
		- Si $donnée = D_{K}(E_{K}(donnée))$ alors $E_{K}$ = $D_{K}$.
		
		> Remarque : les clés de chiffrement et de déchiffrement sont identiques et doivent être gardées secrètes.
	
- Système de cryptage asymétrique :

	- Distinguer une clé publique $PK$ une clé privée (secrète) $SK$.
	
	- Par exemple, Alice veut envoyer un message $donnée$ à Bob, elle envoie le contenu suivant :
	
		- $[PK_{Bob}(donnée), SK_{Alice}(donnée)]$.
	
	- En reprenant l'exemple ci-dessus, à la réception Bob fait les actions suivantes :
	
		- Décrypte le message en appliquant $SK_{Bob}(PK_{Bob}(donnée))$.
	
		- Vérifie que le message provient de Alice en vérifiant que $SK_{Bob}(PK_{Bob}(donnée)) = PK_{Alice}(SK_{Alice}(donnée))$.


### 2.4 Évolutivité dans les systèmes distribués

- Observation :

	- De nombreux développeurs de systèmes répartis modernes utilisent facilement l’adjectif « évolutif » sans expliquer clairement pourquoi leur système évolue réellement.

- Au moins trois composants :

	- Nombre d’utilisateurs ou de processus (évolutivité de taille).
	
	- Distance maximale entre les nœuds (évolutivité géographique).
	
	- Nombre de domaines administratifs (évolutivité administrative).

- D'autres observations :

	- La plupart des systèmes ne tiennent compte, dans une certaine mesure, que de l’évolutivité de la taille.
	
	- Souvent une solution : plusieurs serveurs puissants fonctionnant indépendamment en parallèle.
	
	- Aujourd’hui, le défi réside toujours dans l’évolutivité géographique et administrative.

#### 2.4.1 Techniques de scalabilité

- Objectif : masquer les latences de communication.

- Utiliser la communication asynchrone :

	- Avoir un gestionnaire distinct pour les réponses entrantes.
	
	- Problème : ce modèle ne convient pas à toutes les applications.

- Partitionner les données et les calculs sur plusieurs machines :

	- Déplacer les calculs vers les clients (applets Java et scripts).
	
	| ![La différence entre laisser un serveur (a) ou un client (b) vérifier les formulaires au fur et à mesure qu'ils sont remplis](./Figures/03.%20Figure%203.png) |
	|:--------------------------------------------------------------------------------------------------------------------------------------------------------------:|
	|           **Figure 3 : La différence entre laisser un serveur (a) ou un client (b) vérifier les formulaires au fur et à mesure qu'ils sont remplis**           |
	
	- Services de nommage décentralisés (DNS).
	
	- Les systèmes d’information décentralisés (WWW).
	
#### 2.4.2 Réplication et mise en cache

- Similitudes et nuances : rendre des copies des données disponibles sur différentes machines.

	- Serveurs de fichiers et bases de données répliquées (réplication).
	
	- Sites Web en miroir (réplication).
	
	- Caches Web (dans les navigateurs et les proxys) (mise en cache).
	
	- Mise en cache des fichiers (au niveau du serveur et du client) (mise en cache).
	
- L’application de la réplication est facile, à l’exception d’une chose :

	- Le fait d’avoir plusieurs copies (en cache ou répliquées) entraîne des incohérences : la modification d’une copie rend cette copie différente du reste.

	- Garder toujours des copies cohérentes de manière générale nécessite une synchronisation globale à chaque modification.
	
	- La synchronisation globale exclut les solutions à grande échelle.

- Observation :

	- Si nous pouvons tolérer les incohérences, nous pouvons réduire le besoin de synchronisation globale, mais la tolérance des incohérences dépend de l’application.